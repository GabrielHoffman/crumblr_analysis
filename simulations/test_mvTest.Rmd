---
title: "Multivariate hypothesis testing for dream()"
author:
- name: "[Gabriel Hoffman](http://gabrielhoffman.github.io)"
  affiliation: | 
    Icahn School of Medicine at Mount Sinai, New York
date: "Run on `r Sys.time()`"
output:
  rmarkdown::html_document:
    highlight: pygments
    toc: false
    toc_depth: 3
    fig_width: 5
---

<!---
cd /Users/gabrielhoffman/workspace/repos/crumblr_analysis/simulations
R

rmarkdown::render('test_mvTest.Rmd')



cd /sc/arion/projects/CommonMind/hoffman/crumblr_analysis/simulations
R
system("ml git; git pull"); rmarkdown::render("test_mvTest.Rmd");

# disable X11

ssh -x sklar1

# https://hoffmg01.hpc.mssm.edu/crumblr_analysis/simulations/test_mvTest.html



--->

```{r setup, echo=FALSE, results="hide"}
knitr::opts_chunk$set(tidy=FALSE, cache=TRUE,
                      dev=c("png", "pdf"),
                      package.startup.message = FALSE,
                      message=FALSE, error=FALSE, warning=TRUE)
```	





```{r load, cache=FALSE}
library(PRROC)
library(remaCor)
library(gridExtra)
library(ggplot2)
library(Rfast)
library(cowplot)
library(variancePartition)
library(purrr)
library(furrr)
library(tidyverse)
library(gtools)
library(aod)

autocorr.mat = function (p, rho){
    mat <- diag(p)
    rho^abs(row(mat) - col(mat))
}

# Simulate error with given variance and correlations
sim_error = function(m, n, rho_error, error_var){
  Epsilon = map(1:n, function(k){
    # create correlation matrix
    Sig = matrix(rho_error, m,m)
    diag(Sig) = 1
    # Sig = autocorr.mat(m, rho_error)

    # scale by variances to get covariance matrix
    s = sqrt(error_var[k,])
    Sig = diag(s) %*% Sig %*% diag(s)

    rmvnorm(1, rep(0, m), Sig)
  })
  do.call(rbind, Epsilon)
}
```

Simulation with 200 samples, 2-12 responses, 1e6 replicates, effect sizes of 0.8 shared across responses, heteroskedastic mearsurement error, and an error correlation between response variables of 0.8. 

# Multivariate hypothesis testing
```{r mvTest1}
plan(multisession, workers = 36)
set.seed(12)
 
n.max = 200 # samples
p = 2 # features
m.values = c(2, 5, 10, 15, 20, 30, 50) # responses
rho = 0 # correlation between covariates
rho_error = .8 # error correlation between responses
n_reps = 1e4
n.values = c(20, 50, 75, 150)

m.values = seq(2, 12, by=4)
n.values = c(200)

Sigma = matrix(rho, p,p)
diag(Sigma) = 1

X = rmvnorm(n.max,rep(0,p), Sigma)
Xdf = as.data.frame(X)
rownames(Xdf) = paste0("sample_", 1:n.max)

form = as.formula(paste('~',paste0(colnames(Xdf), collapse=' + ')))

methods = c("sidak", "fisher") 
shrink.methods = c("FALSE", "Schafer", "OAS", "RBLW", "EB")

res = future_map_dfr( seq(n_reps), function(i){

  message('\r', i, '   ', appendLF=FALSE)
  RhpcBLASctl::omp_set_num_threads(1)

  map_df( m.values, function(m){

    # Error variance
    error_var = matrix(runif(n.max*m, 1, 25), n.max, m)
    # error_var[] = 1

    Epsilon = sim_error(m, n.max, rho_error, error_var)

    values = m
    if(i < n_reps*0.9) values = 0

    map_df( values, function(n_positive){

      if(n_positive == 0){
        beta = matrix(0, p,m)
      }else{    
        beta = matrnorm(p,m)/10
        beta[p,] = .8
        # set to zero
        # beta[p,] = 0
        # beta[p,sample.int(m, n_positive)] = 1
      }

      # linear predictor with no noise
      Eta = X %*% beta
      colnames(Eta) = paste0("gene_", 1:m)
      rownames(Eta) = paste0("sample_", 1:n.max)

      # Observe data with error
      Y = Eta + Epsilon

      # Create EList object
      vobj = new("EList", list(E = t(Y), weights = t(1/error_var)))
      vobj$weights[] = 1

      map_df( n.values, function(n){
        idx = seq(n)
        # run dream
        suppressMessages(fit <- dream(vobj[,idx], form, data=Xdf[idx,]))
        fit = eBayes(fit)
        
        res = map_df(methods, function(method){
          mvTest(fit, vobj[,idx], rownames(fit), coef="V2", method)
        })
        res$i = i
        res$n_positive = n_positive
        res$shrink.cov = 'FALSE'
        res$n = n

        res2 = map_df(shrink.methods, function(shrink){
          a = mvTest(fit, vobj[,idx], rownames(fit), coef="V2", method="FE", shrink.cov=shrink)
          a$shrink.cov = shrink
          a
        })
        res2$i = i
        res2$n_positive = n_positive
        res2$n = n

        # S = vcov(fit, vobj[,idx], coef="V2")
        # P = vcovSqrt(fit, vobj[,idx], coef="V2", approx=TRUE)
        # range(S - crossprod(P))

        # corpcor::estimate.lambda(P, verbose=FALSE)
        # CovTools::CovEst.2010RBLW(P)$rho
        # decorrelate::eclairs(P, n.samples = n)$lambda
        
        # standard tests
        df = data.frame(method = c("anova", "wald"), n_features = res$n_features[1], i = i, n_positive = n_positive, shrink.cov = 'FALSE', n=n)
       
        rdf = mean(fit$df.residual)
        
        df$pvalue = c(NA, NA)

        fitlm = lm( t(vobj$E[,idx]) ~ V1 + V2, Xdf[idx,])

        df$pvalue[1] = tryCatch(anova(fitlm)$`Pr(>F)`[3], 
                      error = function(e) NA)

        beta = coef(fitlm)[3,]
        V = vcov(fitlm)
        idx2 = grep(":V2$", rownames(V))
        V = V[idx2,idx2]

        df$pvalue[2] = tryCatch({
              a = wald.test(V, beta, Terms=seq(length(beta)), df=rdf)
              a$result$Ftest['P']},
              error = function(e) NA)
        df$pvalue = as.numeric(df$pvalue)
        

        # residuals(fitlm)[1:3,]
        # # trace("vcov", browser, exit=browser, signature = c("MArrayLM"))
        # # untrace("vcov", signature = c("MArrayLM"))
        # S = vcov(fit, vobj[,idx], coef="V2")

        # coef(fitlm)
        # t(coef(fit))

        # coef(fitlm)
        
        smartbind(rbind(res, res2), df)
      })
    })
  })
},.options = furrr_options(seed=TRUE))
```


```{r FPR, cache=FALSE}
df = res %>%
  filter(n_positive==0) %>%  
  mutate(method2 = paste(method, shrink.cov)) %>%
  group_by(method2, n_features, n) %>%
  summarize( count = sum(pvalue < 0.05), total=length(pvalue)) %>%
  mutate(FPR = count / total) %>%
  mutate( se = sqrt(FPR*(1-FPR)/ total))

fig_FPR = ggplot(df, aes(jitter(n_features), FPR, color=method2)) +
  geom_line(size=1) + 
  geom_point() +
  geom_hline(yintercept=0.05, linetype="dashed") +
  theme_classic() +
  theme(aspect.ratio=1) +
  scale_color_brewer(palette = "Set1") +
  scale_y_continuous("False positive rate", limits=c(0, NA), expand=c(0,0)) +
  scale_x_continuous("Number of responses") +
  scale_alpha_manual(values = c(.3, 1)) +
  facet_wrap(~n, nrow=1)
```





```{r AUPR, fig.height=5, fig.width=10, cache=FALSE}
calc_aupr = function(pvalues, category){

  pr = pr.curve(-log10(pvalues)[!category], -log10(pvalues)[category], rand.compute=TRUE, curve=TRUE)

  pr$auc.integral
}

df2 = map_df(unique(res$n_positive)[-1], function(n_pos){
  res %>%
    filter(n_positive %in% c(0,n_pos)) %>%
    filter(!is.na(pvalue)) %>%
    mutate(method2 = paste(method, shrink.cov)) %>%
    group_by(method2, n) %>%
    summarize( AUPR = calc_aupr(pvalue, n_positive==0)) %>% 
    mutate(n_positive = n_pos)
}) 

fig_AUPR = ggplot(df2, aes(jitter(n_positive), AUPR, color=method2)) +
  geom_line(size=1) + 
  geom_point() +
  geom_hline(yintercept=0.1, linetype="dashed") +
  theme_classic() +
  theme(aspect.ratio=1) +
  scale_color_brewer(palette = "Set1") +
  scale_y_continuous(limits=c(0, 1), expand=c(0,0)) +
  scale_x_continuous("Number of responses") +
  scale_alpha_manual(values = c(.3, 1)) +
  facet_wrap(~n, nrow=1)
```

```{r combine, fig.height=5, fig.width=16, cache=FALSE}
fig_AUPR
fig_FPR
```


OAS, RBLW
divide by n or n-1
is covariance correct?
When is FE better?

<!---


system("ml git; git pull"); rmarkdown::render("test_mvTest.Rmd");



--->






